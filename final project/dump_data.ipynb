{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "DATA_URL = \"http://ciir.cs.umass.edu/downloads/poetry/poetry50k.dedup.jsonl.gz\"\n",
    "data_50k = []\n",
    "\n",
    "\n",
    "def read_data(target):\n",
    "    handle = urllib.request.urlopen(DATA_URL)\n",
    "    with gzip.GzipFile(fileobj=handle) as fp:\n",
    "        for line in fp:\n",
    "            content = json.loads(line)\n",
    "            if content[\"score\"]>0.65:\n",
    "                target.append(content[\"text\"]) \n",
    "                \n",
    "read_data(data_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_50k = data_50k[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^Dedication\\nHere\\ts\\ta\\trhyme\\tfor\\tBarbara,\\nLaughing\\twhite\\tand\\tpink,\\nHere\\ts\\ta\\trhyme\\tfor\\tsmiling\\tTed,\\nAnd\\tone\\tfor\\tWink.\\nNow\\tDick\\ts\\tnot\\tmuch\\tat\\treading\\trhymes,\\nHe\\td\\trather\\tsit\\tand\\tfish.\\nWell,\\there\\ts\\ta\\tcouple\\tof\\tverses,\\tDick,\\nRead\\tthem\\tif\\tyou\\twish!\\n479468\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_50k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1000=data_50k[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "line_break = re.compile(r\"(\\n|<br />)\")\n",
    "\n",
    "\n",
    "def build_dictionary(database, weights):\n",
    "    \n",
    "    dictionary = {}\n",
    "    sentence_length_dictionary={}\n",
    "    \n",
    "    punctuations = '''!()-+='[]{};:\"\\,<>./?@#$%^&*_~1234567890«»|'''\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    prev_words=[\"\",\"\",\"\",\"\"]\n",
    "\n",
    "    for poem in database:\n",
    "        lines = re.split(line_break, poem)\n",
    "\n",
    "        # first lines are usually titles\n",
    "        for line in lines[1:]:    \n",
    "            line = line.replace(\"\\n\",\"\")\n",
    "            line = line.translate(translator)\n",
    "            newline = True          \n",
    "            index = 0\n",
    "            words = line.split('\\t')\n",
    "            for word in words:\n",
    "                if word:\n",
    "                    if not word == \"I\":\n",
    "                        word = word.lower()\n",
    "\n",
    "                    if newline:\n",
    "\n",
    "                        if len(words) in sentence_length_dictionary:\n",
    "                            sentence_length_dictionary[len(words)] +=1\n",
    "                        else:\n",
    "                            sentence_length_dictionary[len(words)] = 1\n",
    "\n",
    "                        for _ in prev_words:\n",
    "                            _ = \"\"\n",
    "                            \n",
    "                        newline = False\n",
    "\n",
    "                    if word in dictionary:\n",
    "                        dictionary[word][\"frequency\"] += 1\n",
    "                    else:\n",
    "                        dictionary[word] = {\n",
    "                                            \"frequency\":1,\n",
    "                                            \"dict\":{}\n",
    "                                            }\n",
    "\n",
    "                    if index >= 2 and not prev_words[1] == \"\":\n",
    "                        if prev_words[1] in dictionary:\n",
    "\n",
    "                            prev_dict2 = dictionary[prev_words[1]][\"dict\"]\n",
    "                            if str((prev_words[0],word)) in prev_dict2:\n",
    "                                prev_dict2[str((prev_words[0],word))] += weights[0]\n",
    "                            else:\n",
    "                                prev_dict2[str((prev_words[0],word))] = weights[0]\n",
    "\n",
    "                        else:\n",
    "                            print(\"preprevious word not in dictionary error\")\n",
    "\n",
    "                    if index >=3 and not prev_words[2] == \"\":\n",
    "\n",
    "                        if prev_words[2] in dictionary :\n",
    "\n",
    "                            prev_dict3 = dictionary[prev_words[2]][\"dict\"]\n",
    "                            if str((prev_words[1], prev_words[0], word)) in prev_dict3:\n",
    "                                prev_dict3[str((prev_words[1], prev_words[0], word))] += weights[1]\n",
    "                            else: \n",
    "                                prev_dict3[str((prev_words[1], prev_words[0], word))] = weights[1]\n",
    "                                \n",
    "                    if index >=4 and not prev_words[3] == \"\":\n",
    "\n",
    "                        if prev_words[3] in dictionary:\n",
    "\n",
    "                            prev_dict4 = dictionary[prev_words[3]][\"dict\"]\n",
    "                            if str((prev_words[2], prev_words[1], prev_words[0], word)) in prev_dict4:\n",
    "                                prev_dict4[str((prev_words[2], prev_words[1], prev_words[0], word))] += weights[2]\n",
    "                            else: \n",
    "                                prev_dict4[str((prev_words[2], prev_words[1], prev_words[0], word))] = weights[2]\n",
    "\n",
    "                    \n",
    "                    for i in range(len(prev_words)-1):\n",
    "                        prev_words[i+1] = prev_words[i]\n",
    "                    prev_words[0] = word\n",
    "                    \n",
    "                    index+=1\n",
    "                    \n",
    "    return dictionary, sentence_length_dictionary\n",
    "\n",
    "dictionary_1k,sl_1k = build_dictionary(data_1000, [1,2,6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary1000.json',\"w\") as out_file:  \n",
    "    json.dump(dictionary_1k, out_file, sort_keys=True, indent=4)\n",
    "\n",
    "with open('sentence_lengthes_1k.json',\"w\") as out_file:  \n",
    "    json.dump(sl_1k, out_file, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_senetnce(dictionary, sentence_len_freq):\n",
    "\n",
    "    sentence = \"\"\n",
    "    sentence_length = random.choices(list(sentence_len_freq.keys()), weights = sentence_len_freq.values(), k=1)[0]\n",
    "    # index a the word in the current sentence\n",
    "    index = 0\n",
    "\n",
    "    word_frequencies = []\n",
    "    for _ in dictionary.values():\n",
    "        word_frequencies.append(_[\"frequency\"])\n",
    "        \n",
    "    first_word = random.choices(list(dictionary.keys()), weights = word_frequencies, k=1)[0]\n",
    "    sentence+=first_word.capitalize()\n",
    "    current_words = [first_word]\n",
    "\n",
    "    while(index < sentence_length-2):\n",
    "        \n",
    "        key = current_words[-1]\n",
    "        while type(key) != str:\n",
    "            key = key[-1]\n",
    "\n",
    "        current_dictionary = dictionary[key][\"dict\"]\n",
    "\n",
    "        if current_dictionary:\n",
    "            current_words = random.choices(list(current_dictionary.keys()),weights = current_dictionary.values(), k=1)\n",
    "            print(current_words)\n",
    "        else: \n",
    "            break\n",
    "\n",
    "\n",
    "        for _ in current_words:\n",
    "            for __ in _[1:]:\n",
    "                sentence = sentence + \" \" + __\n",
    "                index += 1\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(length, dictionary, sentence_len_freq):\n",
    "    \n",
    "    for _ in range(length):\n",
    "        sentence = new_senetnce(dictionary, sentence_len_freq)\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(15, dictionary_50k, sentence_lengthes_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
