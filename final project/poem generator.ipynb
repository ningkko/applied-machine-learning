{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "punctuations = '''!()-[]{};:\"\\,<>./?@#$%^&*_~134567890«»|'''\n",
    "\n",
    "index = 1\n",
    "dictionary = {}\n",
    "first_words=[]\n",
    "last_words=[]\n",
    "sentence_lengthes = []\n",
    "\n",
    "previous_word = \"\"\n",
    "line_length = 0\n",
    "\n",
    "with open('shakespeare.txt','r') as f:\n",
    "    \n",
    "    for line in f:\n",
    "        newline = True          \n",
    "        \n",
    "        for word in line.split():\n",
    "            \n",
    "            word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "            word = word.lower()\n",
    "            \n",
    "            \n",
    "            if newline:\n",
    "                sentence_lengthes.append(line_length)\n",
    "                line_length = 0\n",
    "                \n",
    "                \n",
    "                if not word in first_words:\n",
    "                    first_words.append(word)\n",
    "                    \n",
    "                if previous_word:\n",
    "                    if not previous_word in last_words:\n",
    "                        last_words.append(previous_word)\n",
    "                    \n",
    "                previous_word = \"\"\n",
    "                newline = False\n",
    "                \n",
    "                \n",
    "            if previous_word:\n",
    "                '''\n",
    "                if previous_word in dictionary:\n",
    "                    previous_word_dictionary = dictionary[previous_word]\n",
    "                    if word in previous_word_dictionary:\n",
    "                        previous_word_dictionary[word] +=1\n",
    "                    else:\n",
    "                        previous_word_dictionary[word] = 1\n",
    "                else:\n",
    "\n",
    "                    dictionary[previous_word] = {word:1}\n",
    "                '''\n",
    "                if previous_word in dictionary:\n",
    "                    dictionary[previous_word].append(word)\n",
    "                else:\n",
    "                    dictionary[previous_word] = []\n",
    "\n",
    "                \n",
    "            if not word in dictionary:\n",
    "                dictionary[word] = []\n",
    "            \n",
    "            previous_word = word\n",
    "            line_length+=1\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_word(current):\n",
    "    \"\"\"returns next possible words\"\"\"\n",
    "    \n",
    "    return random.choice(dictionary[current])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_senetnce():\n",
    "    MAX_MATCHING_TIME = int(len(last_words)/50)\n",
    "\n",
    "    sentence = \"\"\n",
    "    sentence_length = random.choice(sentence_lengthes)\n",
    "    # index of the word oin the current sentence\n",
    "    index = 0\n",
    "\n",
    "    first_word = random.choice(first_words)\n",
    "    sentence+=first_word.capitalize()\n",
    "    current_word = first_word\n",
    "    okay_to_end = False\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        if okay_to_end:\n",
    "            break\n",
    "\n",
    "        if index < sentence_length:\n",
    "            \n",
    "            current_dictionary = dictionary[current_word]\n",
    "            if current_dictionary:\n",
    "                current_word = random.choice(current_dictionary)\n",
    "            else: \n",
    "                break\n",
    "                \n",
    "        else:\n",
    "\n",
    "            possible_next = dictionary[current_word]\n",
    "            new_word = random.choice(last_words)\n",
    "            okay_to_end = True\n",
    "\n",
    "            trial = 0 \n",
    "            while (new_word not in possible_next):\n",
    "                new_word = random.choice(last_words)\n",
    "                trial += 1\n",
    "                if trial > MAX_MATCHING_TIME:\n",
    "                    okay_to_end = False\n",
    "                    break\n",
    "\n",
    "            current_word = new_word\n",
    "\n",
    "        sentence=sentence+\" \"+current_word\n",
    "        index += 1\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afternoon as thou taught me tell me asleep decrees boatswain births condition dear encounter\n",
      "Repurchased with wealth\n",
      "Marshal demand that like which stands\n",
      "Moneys a title to bedward\n",
      "Marcius should be chaste body shows best can learn\n",
      "Afternoon of love goes hard to my servants true tis\n",
      "Ild say i would half\n",
      "Duck with you have come on thee gone already sovereign whom\n",
      "Cozen somebody ratcliff i spilld o who wrought commonly unswept degrees wound right but\n",
      "Intended fire is stoppd\n",
      "Remembering my lord of it not up in zeal and confirm\n",
      "An hour englishmen spirit spring thimble some have\n",
      "Fall out of this is entertaind revenge mock return be\n",
      "Relenting fool fool of justice youre powerful spirit in me to pieces\n",
      "Fellows in that devils crest a feather from london\n",
      "Hanging thee in the deadly blot out three thousand curbs suitor greater rheum finishd prosecute beast depends forthcoming gipsy windingsheet trance election france painful up on\n",
      "Bowling it unconstraind\n",
      "Hours hence is no man are content train foldsin flag hats rend prize accursed unswept ruind counterfeit back that\n",
      "Puts some causes\n",
      "Vaughan grey his fortune and to unsay what is norfolk\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    sentence=new_senetnce()\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "DATA_URL = \"http://ciir.cs.umass.edu/~jfoley/truth+text.jsonl.gz\"\n",
    "\n",
    "data = []\n",
    "\n",
    "handle = urllib.request.urlopen(DATA_URL)\n",
    "with gzip.GzipFile(fileobj=handle) as fp:\n",
    "    for line in fp:\n",
    "        data.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': 'adventuresofyoun00biariala',\n",
       " 'page': 50,\n",
       " 'label': 'NOT-POETRY',\n",
       " 'features': {'cap_lines_mean': 0.2,\n",
       "  'left_margin_total': 2.2289156627,\n",
       "  'cap_letters': 0.0248292986,\n",
       "  'num_words': 372.0,\n",
       "  'right_margin_stddev': 0.1131501057,\n",
       "  'cap_lines_stddev': 0.4,\n",
       "  'cap_words_count': 372.0,\n",
       "  'right_margin_count': 35.0,\n",
       "  'right_margin_max': 0.8728915663,\n",
       "  'page_fraction': 0.0992063492,\n",
       "  'right_margin_mean': 0.8470051635,\n",
       "  'alphanum_letters': 0.9596523898,\n",
       "  'left_margin_stddev': 0.041462634,\n",
       "  'words_per_line_mean': 10.6285714286,\n",
       "  'cap_words_max': 1.0,\n",
       "  'cap_words_mean': 0.0672043011,\n",
       "  'cap_words_total': 25.0,\n",
       "  'scaled_punct': 58.0,\n",
       "  'cap_lines_count': 35.0,\n",
       "  'left_margin_count': 35.0,\n",
       "  'words_per_line_total': 372.0,\n",
       "  'words_per_line_count': 35.0,\n",
       "  'right_margin_total': 29.6451807229,\n",
       "  'words_per_line_min': 1.0,\n",
       "  'cap_lines_total': 7.0,\n",
       "  'left_margin_max': 0.3,\n",
       "  'stopwords': 0.5295698925,\n",
       "  'left_margin_mean': 0.0636833046,\n",
       "  'cap_words_min': 0.0,\n",
       "  'digits_letters': 0.0024829299,\n",
       "  'right_margin_min': 0.2,\n",
       "  'cap_lines_max': 1.0,\n",
       "  'words_per_line_stddev': 2.6628203554,\n",
       "  'left_margin_min': 0.0524096386,\n",
       "  'cap_lines_min': 0.0,\n",
       "  'scaled_len': 1.7740098026,\n",
       "  'words_per_line_max': 14.0,\n",
       "  'cap_words_stddev': 0.250375484},\n",
       " 'words': 'A\\tYOUNG\\tNATUMAL1ST.\\t45\\t<br />\\tI\\trestrained\\this\\tardor,\\tas\\tI\\twished\\tto\\tkeep\\tour\\tboxes\\tand\\t<br />\\tneedles\\tfree\\tfor\\tthe\\trarer\\tspecies\\twhich\\twe\\tmight\\texpect\\tto\\t<br />\\tfind\\tas\\tsoon\\tas\\twe\\thad\\treached\\tmore\\tuninhabited\\tdistricts.\\t<br />\\tAt\\tlast,\\tlagging\\ta\\tlittle,\\tour\\tparty\\treached\\tthe\\tfoot\\tof\\tthe\\t<br />\\tmountains.\\t<br />\\tIt\\twas\\tno\\\\v\\tfive\\to\\'clock\\t;\\tnight\\twas\\tcoming\\ton,\\tso\\tit\\twas\\t<br />\\thighly\\tnecessary\\tto\\tlook\\tout\\tfor\\tshelter.\\tWe\\tcame\\tin\\tview\\t<br />\\tof\\ta\\tbamboo-hut\\tin\\tthe\\tnick\\tof\\ttime.\\tAn\\told\\tIndian\\twas\\t<br />\\treclining\\tin\\tfront\\tof\\tit,\\twarming\\this\\tmeagre\\tlimbs\\tin\\tthe\\trays\\t<br />\\tof\\tthe\\tsetting\\tsun,\\tclad\\tin\\tnothing\\tbut\\ta\\tpair\\tof\\tdrawers\\tand\\t<br />\\ta\\that\\twith\\ta\\ttorn\\tbrim.\\tHe\\trose\\tas\\twe\\tcame\\tnear,\\tand\\tprof-\\t<br />\\tfered\\tus\\thospitality.\\tHis\\twife,\\twhose\\tcostume\\tconsisted\\tof\\t<br />\\ta\\tcotton\\tshirt\\tedged\\twith\\tred\\tthread,\\tcame\\trunning\\tin\\tanswer\\t<br />\\tto\\this\\tcall,\\tand\\twas\\tquite\\tin\\traptures\\tat\\tthe\\tprettiness\\tof\\tthe\\t<br />\\t\"\\tlittle\\twhite\\ttraveller,\"\\twho\\tcompletely\\tingratiated\\thimself\\t<br />\\tby\\tsaluting\\ther\\tin\\ther\\town\\tlanguage.\\t\"We\\thad\\taccomplish-\\t<br />\\ted\\ta\\tjourney\\tof\\tseven\\tleagues,\\talthough\\tLucien,\\tthanks\\tto\\t<br />\\tDon\\tAntonio\\'s\\thorse,\\thad\\tnot\\twalked\\tquite\\tso\\tfar.\\t<br />\\tThe\\taborigines\\tset\\tbefore\\tus\\trice\\tand\\tbeans.\\tAfter\\tthis\\t<br />\\tfrugal\\trepast,\\tCashed\\tdown\\twith\\tcold\\twater,\\tI\\twanted\\tLucien\\t<br />\\tto\\tlie\\tdown\\ton\\ta\\tlarge\\tmat\\t;\\tbut\\tthe\\trestless\\tlittle\\tbeing\\ttook\\t<br />\\tadvantage\\tof\\this\\telders\\tbeing\\tcomfortably\\tstretched\\tout\\tto\\t<br />\\tsleep,\\tand\\tran\\toff\\tto\\tsee\\tour\\thostess\\'s\\tfowls\\troosting\\tfor\\tthe\\t<br />\\tnight\\ton\\ta\\tdead\\ttree,\\tand\\tthen\\tto\\tprowl\\tup\\tand\\tdown\\tin\\tcom-\\t<br />\\tpany\\twith\\t1\\'Encuerado.\\tThe\\tlatter\\thad\\tferreted\\tout\\ta\\tthree-\\t<br />\\tcorded\\tguitar\\twhich\\twas\\tin\\tthe\\thut,\\tand\\tstrummed\\taway\\tat\\t<br />\\tthe\\tsame\\ttune\\tfor\\thours\\ttogether\\tno\\tdoubt\\tto\\tthe\\tgreat\\t<br />\\tpleasure\\tof\\tthe\\tboy,\\talthough\\tto\\tus\\tit\\twas\\tquite\\tthe\\treverse.\\t<br />\\tAt\\tlast\\tour\\tbedding\\twas\\tunrolled,\\tand\\tI\\tenjoined\\trepose\\t<br />\\ton\\tall.\\tGringalet\\tcouched\\tdown\\tin\\tthe\\thut,\\tat\\tthe\\tfeet\\tof\\t<br />\\this\\tyoung\\tmaster.\\tL\\'Encuerado,\\thowever,\\tpreferred\\tsleep-\\t<br />\\ting\\tin\\tthe\\topen\\tair,\\tonly\\ttoo\\thappy,\\tas\\the\\tsaid,\\tto\\tsee\\tthe\\t<br />\\tsk\\'y\\tabove,\\tand\\tto\\tfeel\\tthe\\twind\\tblow\\tstraight\\tinto\\this\\tface\\t<br />\\twithout\\thaving\\tto\\tbe\\tfiltered\\tthrough\\twalls\\tand\\twindows.\\t<br />'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems=[]\n",
    "for _ in data:\n",
    "    if _['label']=='POETRY':\n",
    "        poems.append(_['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOMENAJE\\tÁ\\tCOLÓN\\t21\\t<br />\\tColón\\ttuvo\\tiniciativa,\\tque\\tnadie\\tvolverá\\tá\\ttener\\tdentro\\tde\\tlos\\tlímites\\tde\\teste\\t<br />\\tplaneta.\\tEsto\\tbasta\\tpara\\tque\\tsu\\tnombre\\tsea\\tglorificado\\tpor\\ttoda\\tla\\thumanidad,\\t<br />\\tperpetuándose,\\tá\\ttravés\\tde\\tlos\\tsiglos,\\ten\\tla\\tmemoria\\tde\\tlas\\tgeneraciones\\tveni-\\t<br />\\tderas.\\t<br />\\tDaniel\\tBalaciart.\\t<br />\\tCreo\\tque\\tsi\\tno\\thubiera\\texistido\\tel\\tNuevo\\tMundo,\\tlo\\thabría\\tcreado\\tDios\\tpara\\t<br />\\tpremiar\\tla\\tfe\\ty\\tla\\tconstancia\\tde\\tColón.\\t<br />\\tFederico\\tBalart.\\t<br />\\tA\\tCOLÓN\\t<br />\\tFuiste\\tun\\tgenio.\\tAl\\tmar\\tun\\tdía\\t<br />\\tTe\\tlanza\\ttu\\tfe\\tvehemente,\\t<br />\\tY\\tel\\tmundo\\tque\\tte\\tforjaste\\t<br />\\tDescubres\\ty\\tá\\tEspaña\\tofreces.\\t<br />\\tY\\thoy,\\trindiéndote\\tjusticia,\\t<br />\\t¡Anda\\tempeñada\\tla\\tgente\\t<br />\\tPor\\tCátedras\\ty\\tAteneos\\t<br />\\tEn\\trebajarte\\tlaureles!\\t<br />\\tF.\\tBarber\\ty\\tBas.\\t<br />\\tMientras\\tpregone\\tcon\\tamor\\tla\\tHistoria\\t<br />\\tlos\\taltos\\thechos\\tque\\trealiza\\tel\\thombre,\\t<br />\\tdirá\\ten\\tletras\\tde\\tluz\\ttu\\tejecutoria:\\t<br />\\t«Si\\thay\\tun\\tnombre\\tinmortal,\\tese\\tes\\tsu\\tnombre.\\t<br />\\tSi\\thay\\tgloria\\tperdurable,\\tesa\\tes\\tsu\\tgloria.»\\t<br />\\tPedro\\tMaría\\tBarrera.\\t<br />\\tEstamos\\tpresenciando\\tun\\thecho\\tque\\tguarda\\tmucha\\trelación,\\tpor\\tsu\\tgrandeza,\\t<br />\\tcon\\tlos\\tque\\tacompañaron\\tá\\tlos\\tprimeros\\tdescubrimientos\\tde\\tlos\\tespañoles\\ty\\tpor-\\t<br />\\ttugueses\\ten\\tAmérica.\\t<br />\\tA\\tlas\\tpuertas\\tde\\tEspaña\\ttenemos\\tel\\tdilatado\\tContinente\\tafricano,\\tdesconocido\\t<br />\\ten\\tsu\\tmayor\\tparte,\\thasta\\thace\\tpocos\\taños,\\tpara\\tel\\tresto\\tdel\\tMundo.\\tVarias\\tnacio-\\t<br />\\tnes\\teuropeas\\tenvían\\texploradores\\tá\\taquellas\\textensas\\tregiones,\\tya\\tcon\\tpropósitos\\t<br />\\tcientíficos,\\tya\\tcomerciales,\\tvaliéndose\\tde\\tlos\\trecursos\\tde\\tla\\tpaz\\tó\\tde\\tlos\\tde\\tla\\tgue-\\t<br />'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po = poems[0:10]\n",
    "po[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_sentence(_lines,threshold):\n",
    "    \n",
    "    if len(_lines)>1:\n",
    "\n",
    "        rand_line = random.choice(_lines)\n",
    "        words = rand_line.split('\\t')\n",
    "        if len(words) >= threshold:\n",
    "            return rand_line\n",
    "        \n",
    "        _lines.remove(rand_line)\n",
    "        return pick_sentence(_lines,threshold)\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        return _lines[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(peom):\n",
    "    plines = peom.split(\"<br />\")\n",
    "    sentence = pick_sentence(plines,4)\n",
    "    try:\n",
    "        language = detect(sentence)\n",
    "    except:\n",
    "        language = ''\n",
    "    return language\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_language(po[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_2k = {}\n",
    "first_words=[]\n",
    "sentence_lengthes = []\n",
    "previous_word = \"\"\n",
    "line_length = 0\n",
    "\n",
    "punctuations = '''!()-[]{};:\"\\,<>./?@#$%^&*_~134567890«»|'''\n",
    "translator = str.maketrans('', '', punctuations)\n",
    "for poem in poems:\n",
    "    if detect_language(poem) == \"en\":\n",
    "        lines = poem.split('<br />')\n",
    "\n",
    "        # first lines are usually titles\n",
    "        for line in lines[1:]:    \n",
    "            line = line.translate(translator)\n",
    "            newline = True          \n",
    "            for word in line.split('\\t'):\n",
    "\n",
    "                if (len(word)>1) or (word == \"I\") :\n",
    "                    #word = word.translate(translator)\n",
    "\n",
    "                    if not word == \"I\":\n",
    "                        word = word.lower()\n",
    "\n",
    "                    if newline:\n",
    "\n",
    "                        sentence_lengthes.append(line_length)\n",
    "                        line_length = 0\n",
    "\n",
    "\n",
    "                        if not word in first_words:\n",
    "                            first_words.append(word)\n",
    "\n",
    "\n",
    "                        previous_word = \"\"\n",
    "                        newline = False\n",
    "\n",
    "\n",
    "                    if previous_word:\n",
    "\n",
    "                        if previous_word in dictionary_2k:\n",
    "                            dictionary_2k[previous_word].append(word)\n",
    "                        else:\n",
    "                            dictionary_2k[previous_word] = []\n",
    "\n",
    "\n",
    "                    if not word in dictionary_2k:\n",
    "                        dictionary_2k[word] = []\n",
    "\n",
    "                    previous_word = word\n",
    "                    line_length+=1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary_2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_senetnce(dictionary):\n",
    "    MAX_MATCHING_TIME = int(len(last_words)/50)\n",
    "\n",
    "    sentence = \"\"\n",
    "    sentence_length = random.choice(sentence_lengthes)\n",
    "    # index of the word oin the current sentence\n",
    "    index = 0\n",
    "\n",
    "    first_word = random.choice(first_words)\n",
    "    sentence+=first_word.capitalize()\n",
    "    current_word = first_word\n",
    "    okay_to_end = False\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        if index < sentence_length:\n",
    "            \n",
    "            current_dictionary = dictionary[current_word]\n",
    "            if current_dictionary:\n",
    "                current_word = random.choice(current_dictionary)\n",
    "            else: \n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "\n",
    "        sentence = sentence + \" \" + current_word\n",
    "        index += 1\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(length):\n",
    "    for _ in range(length):\n",
    "        sentence = new_senetnce(dictionary_2k)\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver +\n",
    "1. To start a sentence with words w/ more next choices and to end one with words w/ fewer choices\n",
    "2. To train the model on larger datasets\n",
    "3. To predict based on multi-words.\n",
    "4. change the list of actual words into a dictionary of word frequencies for memory efficiency\n",
    "5. Use numpy - randomchoice (with probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "DATA_URL = \"http://ciir.cs.umass.edu/downloads/poetry/poetry50k.dedup.jsonl.gz\"\n",
    "data_50k = []\n",
    "\n",
    "\n",
    "def read_data(target):\n",
    "    handle = urllib.request.urlopen(DATA_URL)\n",
    "    with gzip.GzipFile(fileobj=handle) as fp:\n",
    "        for line in fp:\n",
    "            content = json.loads(line)\n",
    "            if content[\"score\"]>0.65:\n",
    "                target.append(content[\"text\"]) \n",
    "                \n",
    "read_data(data_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_50k = data_50k[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_50k = {}\n",
    "sentence_lengthes_50k = {}\n",
    "\n",
    "import re\n",
    "line_break = re.compile(r\"(\\n|<br />)\")\n",
    "\n",
    "\n",
    "def build_dictionary(database, sentence_len_freq):\n",
    "    punctuations = '''!()-[]{};:\"\\,<>./?@#$%^&*_~134567890«»|'''\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    \n",
    "    for poem in database:\n",
    "        lines = re.split(line_break, poem)\n",
    "\n",
    "        prev_word = \"\"\n",
    "        preprev_word = \"\"\n",
    "        prepreprev_word = \"\"\n",
    "        \n",
    "        # first lines are usually titles\n",
    "        for line in lines[1:]:    \n",
    "            line = line.translate(translator)\n",
    "            newline = True          \n",
    "            index = 0\n",
    "\n",
    "            for word in line.split('\\t'):\n",
    "\n",
    "                if not word == \"I\":\n",
    "                    word = word.lower()\n",
    "\n",
    "                if newline:\n",
    "\n",
    "                    if len(line) in sentence_len_freq:\n",
    "                        sentence_len_freq[len(line)] +=1\n",
    "                    else:\n",
    "                        sentence_len_freq[len(line)]=1\n",
    "\n",
    "                    prev_word = \"\"\n",
    "                    preprev_word = \"\"\n",
    "                    prepreprev_word = \"\"\n",
    "                    newline = False\n",
    "\n",
    "                if word in dictionary_50k:\n",
    "                    dictionary_50k[word][\"frequency\"] += 1\n",
    "                else:\n",
    "                    dictionary_50k[word] = {\n",
    "                                            \"frequency\":1,\n",
    "                                            \"dict\":{}\n",
    "                                            }\n",
    "                    \n",
    "                if index >= 2:\n",
    "                    if preprev_word in dictionary_50k:\n",
    "\n",
    "                        preprev_dict = dictionary_50k[preprev_word][\"dict\"]\n",
    "                        if (prev_word,word) in preprev_dict:\n",
    "                            preprev_dict[(prev_word,word)]+=1\n",
    "                        else:\n",
    "                            preprev_dict[(prev_word,word)] = 1\n",
    "\n",
    "                    else:\n",
    "                        print(\"preprevious word not in dictionary error\")\n",
    "                \n",
    "                if index >=3:\n",
    "                    \n",
    "                    if prepreprev_word in dictionary_50k:\n",
    "                        \n",
    "                        prepreprev_dict = dictionary_50k[prepreprev_word][\"dict\"]\n",
    "                        if (prepreprev_word, prev_word, word) in prepreprev_dict:\n",
    "                            prepreprev_dict[(prepreprev_word, prev_word, word)] += 1\n",
    "                        else: \n",
    "                            prepreprev_dict[(prepreprev_word, prev_word, word)] = 1\n",
    "                        \n",
    "                \n",
    "                prepreprev_word = preprev_word\n",
    "                preprev_word = prev_word\n",
    "                prev_word = word\n",
    "                index+=1\n",
    "                \n",
    "build_dictionary(data_50k, sentence_lengthes_50k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "keys must be str, int, float, bool or None, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-84cf5438f547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dictionary50k.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictionary_50k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentence_lengthes_50k.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_lengthes_50k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 raise TypeError(f'keys must be str, int, float, bool or None, '\n\u001b[0m\u001b[1;32m    377\u001b[0m                                 f'not {key.__class__.__name__}')\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: keys must be str, int, float, bool or None, not tuple"
     ]
    }
   ],
   "source": [
    "with open('dictionary50k.txt',\"w\") as out_file:  \n",
    "    json.dump({str(key): value for key, value in dictionary_50k.items()}, out_file, sort_keys=True, indent=4)\n",
    "\n",
    "with open('sentence_lengthes_50k.txt',\"w\") as out_file:  \n",
    "    json.dump(sentence_lengthes_50k, out_file, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_senetnce(dictionary, sentence_len_freq):\n",
    "\n",
    "    sentence = \"\"\n",
    "    sentence_length = random.choices(list(sentence_len_freq.keys()), weights = sentence_len_freq.values(), k=1)[0]\n",
    "    # index a the word in the current sentence\n",
    "    index = 0\n",
    "\n",
    "    word_frequencies = []\n",
    "    for _ in dictionary.values():\n",
    "        word_frequencies.append(_[\"frequency\"])\n",
    "        \n",
    "    first_word = random.choices(list(dictionary.keys()), weights = word_frequencies, k=1)[0]\n",
    "    sentence+=first_word.capitalize()\n",
    "    current_words = [first_word]\n",
    "\n",
    "    while(index < sentence_length-2):\n",
    "        \n",
    "        key = current_words[-1]\n",
    "        while type(key) != str:\n",
    "            key = key[-1]\n",
    "\n",
    "        current_dictionary = dictionary[key][\"dict\"]\n",
    "\n",
    "        if current_dictionary:\n",
    "            current_words = random.choices(list(current_dictionary.keys()),weights = current_dictionary.values(), k=1)\n",
    "            print(current_words)\n",
    "        else: \n",
    "            break\n",
    "\n",
    "\n",
    "        for _ in current_words:\n",
    "            for __ in _[1:]:\n",
    "                sentence = sentence + \" \" + __\n",
    "                index += 1\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(length, dictionary, sentence_len_freq):\n",
    "    \n",
    "    for _ in range(length):\n",
    "        sentence = new_senetnce(dictionary, sentence_len_freq)\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_poem(15, dictionary_50k, sentence_lengthes_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
