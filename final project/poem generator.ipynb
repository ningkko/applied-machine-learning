{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "punctuations = '''!()-[]{};:\"\\,<>./?@#$%^&*_~134567890«»|'''\n",
    "\n",
    "index = 1\n",
    "dictionary = {}\n",
    "first_words=[]\n",
    "last_words=[]\n",
    "sentence_lengthes = []\n",
    "\n",
    "previous_word = \"\"\n",
    "line_length = 0\n",
    "\n",
    "with open('shakespeare.txt','r') as f:\n",
    "    \n",
    "    for line in f:\n",
    "        newline = True          \n",
    "        \n",
    "        for word in line.split():\n",
    "            \n",
    "            word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "            word = word.lower()\n",
    "            \n",
    "            \n",
    "            if newline:\n",
    "                sentence_lengthes.append(line_length)\n",
    "                line_length = 0\n",
    "                \n",
    "                \n",
    "                if not word in first_words:\n",
    "                    first_words.append(word)\n",
    "                    \n",
    "                if previous_word:\n",
    "                    if not previous_word in last_words:\n",
    "                        last_words.append(previous_word)\n",
    "                    \n",
    "                previous_word = \"\"\n",
    "                newline = False\n",
    "                \n",
    "                \n",
    "            if previous_word:\n",
    "                '''\n",
    "                if previous_word in dictionary:\n",
    "                    previous_word_dictionary = dictionary[previous_word]\n",
    "                    if word in previous_word_dictionary:\n",
    "                        previous_word_dictionary[word] +=1\n",
    "                    else:\n",
    "                        previous_word_dictionary[word] = 1\n",
    "                else:\n",
    "\n",
    "                    dictionary[previous_word] = {word:1}\n",
    "                '''\n",
    "                if previous_word in dictionary:\n",
    "                    dictionary[previous_word].append(word)\n",
    "                else:\n",
    "                    dictionary[previous_word] = []\n",
    "\n",
    "                \n",
    "            if not word in dictionary:\n",
    "                dictionary[word] = []\n",
    "            \n",
    "            previous_word = word\n",
    "            line_length+=1\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_word(current):\n",
    "    \"\"\"returns next possible words\"\"\"\n",
    "    \n",
    "    return random.choice(dictionary[current])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_senetnce():\n",
    "    MAX_MATCHING_TIME = int(len(last_words)/50)\n",
    "\n",
    "    sentence = \"\"\n",
    "    sentence_length = random.choice(sentence_lengthes)\n",
    "    # index of the word oin the current sentence\n",
    "    index = 0\n",
    "\n",
    "    first_word = random.choice(first_words)\n",
    "    sentence+=first_word.capitalize()\n",
    "    current_word = first_word\n",
    "    okay_to_end = False\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        if okay_to_end:\n",
    "            break\n",
    "\n",
    "        if index < sentence_length:\n",
    "            \n",
    "            current_dictionary = dictionary[current_word]\n",
    "            if current_dictionary:\n",
    "                current_word = random.choice(current_dictionary)\n",
    "            else: \n",
    "                break\n",
    "                \n",
    "        else:\n",
    "\n",
    "            possible_next = dictionary[current_word]\n",
    "            new_word = random.choice(last_words)\n",
    "            okay_to_end = True\n",
    "\n",
    "            trial = 0 \n",
    "            while (new_word not in possible_next):\n",
    "                new_word = random.choice(last_words)\n",
    "                trial += 1\n",
    "                if trial > MAX_MATCHING_TIME:\n",
    "                    okay_to_end = False\n",
    "                    break\n",
    "\n",
    "            current_word = new_word\n",
    "\n",
    "        sentence=sentence+\" \"+current_word\n",
    "        index += 1\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showd it you will stay to have done sir will\n",
      "Plots have known before i know for him we charged\n",
      "Wanting of king henry vi\n",
      "Whipt and all will be shrouded in our soldier confidence visage joseph upright apart further avoid patrician villagecock fellowtribune no tongue\n",
      "Sham it proceed\n",
      "Crowns since widow dido said needful servant in\n",
      "Senators have bought it were of the nuptial repined weatherbitten ourself usurer certainly bachelor realm of\n",
      "Served you as longeth to say she may if\n",
      "Guard like the centre out to be patient as the truth argosy rare note\n",
      "Dicky your presence and from scotland hath been preserved souls allaying tongueless highway nap fertile shouts nursed woe and\n",
      "Commands me too childishfoolish for a virtue of your clothes walnutshell bleeds deputyelect garden injustice lets harbour\n",
      "Theno i marvel why whos here is shall fly from london\n",
      "Honesty nor what shrillvoiced suppliant may curtsy delayd shut straws bachelor sir\n",
      "Certainty yet performd me or seven thousand escapes of thyself\n",
      "Fly ah montague it henry vi\n",
      "Peace the young hot the duke vincentio now follows\n",
      "My good markman and truth\n",
      "Tomorrow or two in thy conscience sir few dagger corioli wear\n",
      "Hands at themselves rememberd hecuba pace award hold shot reasons games soars fertile judgmentplace cupbearer desperation avoid come\n",
      "Whenever buckingham to\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    sentence=new_senetnce()\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "DATA_URL = \"http://ciir.cs.umass.edu/~jfoley/truth+text.jsonl.gz\"\n",
    "\n",
    "data = []\n",
    "\n",
    "handle = urllib.request.urlopen(DATA_URL)\n",
    "with gzip.GzipFile(fileobj=handle) as fp:\n",
    "    for line in fp:\n",
    "        data.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': 'adventuresofyoun00biariala',\n",
       " 'page': 50,\n",
       " 'label': 'NOT-POETRY',\n",
       " 'features': {'cap_lines_mean': 0.2,\n",
       "  'left_margin_total': 2.2289156627,\n",
       "  'cap_letters': 0.0248292986,\n",
       "  'num_words': 372.0,\n",
       "  'right_margin_stddev': 0.1131501057,\n",
       "  'cap_lines_stddev': 0.4,\n",
       "  'cap_words_count': 372.0,\n",
       "  'right_margin_count': 35.0,\n",
       "  'right_margin_max': 0.8728915663,\n",
       "  'page_fraction': 0.0992063492,\n",
       "  'right_margin_mean': 0.8470051635,\n",
       "  'alphanum_letters': 0.9596523898,\n",
       "  'left_margin_stddev': 0.041462634,\n",
       "  'words_per_line_mean': 10.6285714286,\n",
       "  'cap_words_max': 1.0,\n",
       "  'cap_words_mean': 0.0672043011,\n",
       "  'cap_words_total': 25.0,\n",
       "  'scaled_punct': 58.0,\n",
       "  'cap_lines_count': 35.0,\n",
       "  'left_margin_count': 35.0,\n",
       "  'words_per_line_total': 372.0,\n",
       "  'words_per_line_count': 35.0,\n",
       "  'right_margin_total': 29.6451807229,\n",
       "  'words_per_line_min': 1.0,\n",
       "  'cap_lines_total': 7.0,\n",
       "  'left_margin_max': 0.3,\n",
       "  'stopwords': 0.5295698925,\n",
       "  'left_margin_mean': 0.0636833046,\n",
       "  'cap_words_min': 0.0,\n",
       "  'digits_letters': 0.0024829299,\n",
       "  'right_margin_min': 0.2,\n",
       "  'cap_lines_max': 1.0,\n",
       "  'words_per_line_stddev': 2.6628203554,\n",
       "  'left_margin_min': 0.0524096386,\n",
       "  'cap_lines_min': 0.0,\n",
       "  'scaled_len': 1.7740098026,\n",
       "  'words_per_line_max': 14.0,\n",
       "  'cap_words_stddev': 0.250375484},\n",
       " 'words': 'A\\tYOUNG\\tNATUMAL1ST.\\t45\\t<br />\\tI\\trestrained\\this\\tardor,\\tas\\tI\\twished\\tto\\tkeep\\tour\\tboxes\\tand\\t<br />\\tneedles\\tfree\\tfor\\tthe\\trarer\\tspecies\\twhich\\twe\\tmight\\texpect\\tto\\t<br />\\tfind\\tas\\tsoon\\tas\\twe\\thad\\treached\\tmore\\tuninhabited\\tdistricts.\\t<br />\\tAt\\tlast,\\tlagging\\ta\\tlittle,\\tour\\tparty\\treached\\tthe\\tfoot\\tof\\tthe\\t<br />\\tmountains.\\t<br />\\tIt\\twas\\tno\\\\v\\tfive\\to\\'clock\\t;\\tnight\\twas\\tcoming\\ton,\\tso\\tit\\twas\\t<br />\\thighly\\tnecessary\\tto\\tlook\\tout\\tfor\\tshelter.\\tWe\\tcame\\tin\\tview\\t<br />\\tof\\ta\\tbamboo-hut\\tin\\tthe\\tnick\\tof\\ttime.\\tAn\\told\\tIndian\\twas\\t<br />\\treclining\\tin\\tfront\\tof\\tit,\\twarming\\this\\tmeagre\\tlimbs\\tin\\tthe\\trays\\t<br />\\tof\\tthe\\tsetting\\tsun,\\tclad\\tin\\tnothing\\tbut\\ta\\tpair\\tof\\tdrawers\\tand\\t<br />\\ta\\that\\twith\\ta\\ttorn\\tbrim.\\tHe\\trose\\tas\\twe\\tcame\\tnear,\\tand\\tprof-\\t<br />\\tfered\\tus\\thospitality.\\tHis\\twife,\\twhose\\tcostume\\tconsisted\\tof\\t<br />\\ta\\tcotton\\tshirt\\tedged\\twith\\tred\\tthread,\\tcame\\trunning\\tin\\tanswer\\t<br />\\tto\\this\\tcall,\\tand\\twas\\tquite\\tin\\traptures\\tat\\tthe\\tprettiness\\tof\\tthe\\t<br />\\t\"\\tlittle\\twhite\\ttraveller,\"\\twho\\tcompletely\\tingratiated\\thimself\\t<br />\\tby\\tsaluting\\ther\\tin\\ther\\town\\tlanguage.\\t\"We\\thad\\taccomplish-\\t<br />\\ted\\ta\\tjourney\\tof\\tseven\\tleagues,\\talthough\\tLucien,\\tthanks\\tto\\t<br />\\tDon\\tAntonio\\'s\\thorse,\\thad\\tnot\\twalked\\tquite\\tso\\tfar.\\t<br />\\tThe\\taborigines\\tset\\tbefore\\tus\\trice\\tand\\tbeans.\\tAfter\\tthis\\t<br />\\tfrugal\\trepast,\\tCashed\\tdown\\twith\\tcold\\twater,\\tI\\twanted\\tLucien\\t<br />\\tto\\tlie\\tdown\\ton\\ta\\tlarge\\tmat\\t;\\tbut\\tthe\\trestless\\tlittle\\tbeing\\ttook\\t<br />\\tadvantage\\tof\\this\\telders\\tbeing\\tcomfortably\\tstretched\\tout\\tto\\t<br />\\tsleep,\\tand\\tran\\toff\\tto\\tsee\\tour\\thostess\\'s\\tfowls\\troosting\\tfor\\tthe\\t<br />\\tnight\\ton\\ta\\tdead\\ttree,\\tand\\tthen\\tto\\tprowl\\tup\\tand\\tdown\\tin\\tcom-\\t<br />\\tpany\\twith\\t1\\'Encuerado.\\tThe\\tlatter\\thad\\tferreted\\tout\\ta\\tthree-\\t<br />\\tcorded\\tguitar\\twhich\\twas\\tin\\tthe\\thut,\\tand\\tstrummed\\taway\\tat\\t<br />\\tthe\\tsame\\ttune\\tfor\\thours\\ttogether\\tno\\tdoubt\\tto\\tthe\\tgreat\\t<br />\\tpleasure\\tof\\tthe\\tboy,\\talthough\\tto\\tus\\tit\\twas\\tquite\\tthe\\treverse.\\t<br />\\tAt\\tlast\\tour\\tbedding\\twas\\tunrolled,\\tand\\tI\\tenjoined\\trepose\\t<br />\\ton\\tall.\\tGringalet\\tcouched\\tdown\\tin\\tthe\\thut,\\tat\\tthe\\tfeet\\tof\\t<br />\\this\\tyoung\\tmaster.\\tL\\'Encuerado,\\thowever,\\tpreferred\\tsleep-\\t<br />\\ting\\tin\\tthe\\topen\\tair,\\tonly\\ttoo\\thappy,\\tas\\the\\tsaid,\\tto\\tsee\\tthe\\t<br />\\tsk\\'y\\tabove,\\tand\\tto\\tfeel\\tthe\\twind\\tblow\\tstraight\\tinto\\this\\tface\\t<br />\\twithout\\thaving\\tto\\tbe\\tfiltered\\tthrough\\twalls\\tand\\twindows.\\t<br />'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems=[]\n",
    "for _ in data:\n",
    "    if _['label']=='POETRY':\n",
    "        poems.append(_['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOMENAJE\\tÁ\\tCOLÓN\\t21\\t<br />\\tColón\\ttuvo\\tiniciativa,\\tque\\tnadie\\tvolverá\\tá\\ttener\\tdentro\\tde\\tlos\\tlímites\\tde\\teste\\t<br />\\tplaneta.\\tEsto\\tbasta\\tpara\\tque\\tsu\\tnombre\\tsea\\tglorificado\\tpor\\ttoda\\tla\\thumanidad,\\t<br />\\tperpetuándose,\\tá\\ttravés\\tde\\tlos\\tsiglos,\\ten\\tla\\tmemoria\\tde\\tlas\\tgeneraciones\\tveni-\\t<br />\\tderas.\\t<br />\\tDaniel\\tBalaciart.\\t<br />\\tCreo\\tque\\tsi\\tno\\thubiera\\texistido\\tel\\tNuevo\\tMundo,\\tlo\\thabría\\tcreado\\tDios\\tpara\\t<br />\\tpremiar\\tla\\tfe\\ty\\tla\\tconstancia\\tde\\tColón.\\t<br />\\tFederico\\tBalart.\\t<br />\\tA\\tCOLÓN\\t<br />\\tFuiste\\tun\\tgenio.\\tAl\\tmar\\tun\\tdía\\t<br />\\tTe\\tlanza\\ttu\\tfe\\tvehemente,\\t<br />\\tY\\tel\\tmundo\\tque\\tte\\tforjaste\\t<br />\\tDescubres\\ty\\tá\\tEspaña\\tofreces.\\t<br />\\tY\\thoy,\\trindiéndote\\tjusticia,\\t<br />\\t¡Anda\\tempeñada\\tla\\tgente\\t<br />\\tPor\\tCátedras\\ty\\tAteneos\\t<br />\\tEn\\trebajarte\\tlaureles!\\t<br />\\tF.\\tBarber\\ty\\tBas.\\t<br />\\tMientras\\tpregone\\tcon\\tamor\\tla\\tHistoria\\t<br />\\tlos\\taltos\\thechos\\tque\\trealiza\\tel\\thombre,\\t<br />\\tdirá\\ten\\tletras\\tde\\tluz\\ttu\\tejecutoria:\\t<br />\\t«Si\\thay\\tun\\tnombre\\tinmortal,\\tese\\tes\\tsu\\tnombre.\\t<br />\\tSi\\thay\\tgloria\\tperdurable,\\tesa\\tes\\tsu\\tgloria.»\\t<br />\\tPedro\\tMaría\\tBarrera.\\t<br />\\tEstamos\\tpresenciando\\tun\\thecho\\tque\\tguarda\\tmucha\\trelación,\\tpor\\tsu\\tgrandeza,\\t<br />\\tcon\\tlos\\tque\\tacompañaron\\tá\\tlos\\tprimeros\\tdescubrimientos\\tde\\tlos\\tespañoles\\ty\\tpor-\\t<br />\\ttugueses\\ten\\tAmérica.\\t<br />\\tA\\tlas\\tpuertas\\tde\\tEspaña\\ttenemos\\tel\\tdilatado\\tContinente\\tafricano,\\tdesconocido\\t<br />\\ten\\tsu\\tmayor\\tparte,\\thasta\\thace\\tpocos\\taños,\\tpara\\tel\\tresto\\tdel\\tMundo.\\tVarias\\tnacio-\\t<br />\\tnes\\teuropeas\\tenvían\\texploradores\\tá\\taquellas\\textensas\\tregiones,\\tya\\tcon\\tpropósitos\\t<br />\\tcientíficos,\\tya\\tcomerciales,\\tvaliéndose\\tde\\tlos\\trecursos\\tde\\tla\\tpaz\\tó\\tde\\tlos\\tde\\tla\\tgue-\\t<br />'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "po = poems[0:10]\n",
    "po[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_sentence(_lines,threshold):\n",
    "    \n",
    "    if len(_lines)>1:\n",
    "\n",
    "        rand_line = random.choice(_lines)\n",
    "        words = rand_line.split('\\t')\n",
    "        if len(words) >= threshold:\n",
    "            return rand_line\n",
    "        \n",
    "        _lines.remove(rand_line)\n",
    "        return pick_sentence(_lines,threshold)\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        return _lines[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(peom):\n",
    "    plines = peom.split(\"<br />\")\n",
    "    sentence = pick_sentence(plines,4)\n",
    "    try:\n",
    "        language = detect(sentence)\n",
    "    except:\n",
    "        language = ''\n",
    "    return language\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_language(po[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_2k = {}\n",
    "first_words=[]\n",
    "sentence_lengthes = []\n",
    "previous_word = \"\"\n",
    "line_length = 0\n",
    "\n",
    "punctuations = '''!()-[]{};:\"\\,<>./?@#$%^&*_~134567890«»|'''\n",
    "translator = str.maketrans('', '', punctuations)\n",
    "for poem in poems:\n",
    "    if detect_language(poem) == \"en\":\n",
    "        lines = poem.split('<br />')\n",
    "\n",
    "        # first lines are usually titles\n",
    "        for line in lines[1:]:    \n",
    "            line = line.translate(translator)\n",
    "            newline = True          \n",
    "            for word in line.split('\\t'):\n",
    "\n",
    "                if (len(word)>1) or (word == \"I\") :\n",
    "                    #word = word.translate(translator)\n",
    "\n",
    "                    if not word == \"I\":\n",
    "                        word = word.lower()\n",
    "\n",
    "                    if newline:\n",
    "\n",
    "                        sentence_lengthes.append(line_length)\n",
    "                        line_length = 0\n",
    "\n",
    "\n",
    "                        if not word in first_words:\n",
    "                            first_words.append(word)\n",
    "\n",
    "\n",
    "                        previous_word = \"\"\n",
    "                        newline = False\n",
    "\n",
    "\n",
    "                    if previous_word:\n",
    "\n",
    "                        if previous_word in dictionary_2k:\n",
    "                            dictionary_2k[previous_word].append(word)\n",
    "                        else:\n",
    "                            dictionary_2k[previous_word] = []\n",
    "\n",
    "\n",
    "                    if not word in dictionary_2k:\n",
    "                        dictionary_2k[word] = []\n",
    "\n",
    "                    previous_word = word\n",
    "                    line_length+=1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary_2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(length):\n",
    "    for _ in range(length):\n",
    "        sentence = new_senetnce(dictionary_2k)\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_senetnce(dictionary):\n",
    "    MAX_MATCHING_TIME = int(len(last_words)/50)\n",
    "\n",
    "    sentence = \"\"\n",
    "    sentence_length = random.choice(sentence_lengthes)\n",
    "    # index of the word oin the current sentence\n",
    "    index = 0\n",
    "\n",
    "    first_word = random.choice(first_words)\n",
    "    sentence+=first_word.capitalize()\n",
    "    current_word = first_word\n",
    "    okay_to_end = False\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        if index < sentence_length:\n",
    "            \n",
    "            current_dictionary = dictionary[current_word]\n",
    "            if current_dictionary:\n",
    "                current_word = random.choice(current_dictionary)\n",
    "            else: \n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "\n",
    "        sentence = sentence + \" \" + current_word\n",
    "        index += 1\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second strove with equal haste haste the\n",
      "Alarms from the welcome heaviness their head the\n",
      "Ljut knew all his lofty steeds unbound our\n",
      "Vafes and the borrow'd name and his god is\n",
      "Follow'd mars armipotent invades the war with alter'd cymon\n"
     ]
    }
   ],
   "source": [
    "generate_poem(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
